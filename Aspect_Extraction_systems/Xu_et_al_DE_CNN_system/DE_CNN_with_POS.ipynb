{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## This notebook adds POS labels for concatenation with input for CNN.\n",
    "It is a proof of concept only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-02T10:07:10.977424Z",
     "start_time": "2020-07-02T10:07:10.967268Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML('<style>.container { width:100% !important; }</style>'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-02T10:07:14.356297Z",
     "start_time": "2020-07-02T10:07:11.368394Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gensim\n",
    "import keras\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv1D, GlobalMaxPooling1D \n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_extraction import DictVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## load data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### load train file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-02T10:09:40.830174Z",
     "start_time": "2020-07-02T10:09:40.786768Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# load in our restaurant tsv - the tsv col - word is our string.\n",
    "path= '/media/peter/BigExternal/Study/Vu/Thesis/code/testing/aspect_extraction/data/2014_rest/'\n",
    "file_train = 'restaurants_train.tsv'\n",
    "df_train = pd.read_csv(path+file_train, sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### load test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-02T10:10:03.608954Z",
     "start_time": "2020-07-02T10:10:03.170237Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# load in test data 2014 - gold\n",
    "file_test = 'restaurants_gold.tsv'\n",
    "df_test = pd.read_csv(path+file_test, sep = '\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### load general embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-02T10:12:40.759562Z",
     "start_time": "2020-07-02T10:11:03.890626Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "path_to_w2v = '/media/peter/BigExternal/Study/Vu/GoogleNews-vectors-negative300.bin/GoogleNews-vectors-negative300.bin'\n",
    "w2v_embedding_model = gensim.models.KeyedVectors.load_word2vec_format(path_to_w2v,binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### domain_embeddings: hsu's fastText model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-02T10:13:15.485571Z",
     "start_time": "2020-07-02T10:12:40.761248Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# these are hsu's 100dim\n",
    "path_to_xu_model = '/media/peter/BigExternal/Study/Vu/Thesis/code/testing/aspect_extraction/DE-CNN-master/data/embedding/restaurant_emb.vec.bin'\n",
    "xu_model = gensim.models.fasttext.load_facebook_model(path_to_xu_model) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## functions to substitute file for  embeds "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-02T10:13:15.489683Z",
     "start_time": "2020-07-02T10:13:15.486813Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#substitute word for embedding vector\n",
    "#substitute zeroes for unknown \n",
    "def embed_swap (word_embedding_model, dataframe_series):\n",
    "    '''takes a word embedding model and a dataframe series or words\n",
    "    returns a list of embeddings in the same order as the series.\n",
    "    '''\n",
    "    embeddings = []\n",
    "    for token in dataframe_series:\n",
    "        if token in word_embedding_model:\n",
    "            vector = word_embedding_model[token]\n",
    "        else:\n",
    "            vector = [0]*300\n",
    "        embeddings.append(vector)\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### function to make labels categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-02T10:13:15.493902Z",
     "start_time": "2020-07-02T10:13:15.490706Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "#labels to categorical\n",
    "def labels_to_categorical (dataframe_series):\n",
    "    '''changes a series of labels into numerical categories and a dictionary to look up the cats\n",
    "    \n",
    "    '''\n",
    "    labels = dataframe_series.tolist()\n",
    "    label_set = set()\n",
    "    for label in labels:\n",
    "        label_set.add(label)\n",
    "    label2Idx = {}\n",
    "    for label in label_set:\n",
    "        label2Idx[label] = len(label2Idx)\n",
    "    map_prep = pd.DataFrame(labels)\n",
    "    mapped = list(map_prep[0].map(label2Idx))\n",
    "    Y_label = np.asarray(mapped)\n",
    "\n",
    "    label2Idx\n",
    "    return Y_label, label2Idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-02T10:13:15.497112Z",
     "start_time": "2020-07-02T10:13:15.494810Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def dicts_n_labels(df, features):\n",
    "    '''\n",
    "    takes a dataframe and a user-generated list of features as input\n",
    "    returns a dictionary of features ready for vecotization, a list of NER labels\n",
    "    and a list of token from the dataframe\n",
    "    '''\n",
    "    no_label = df[features]\n",
    "    dict_for_vec = no_label.to_dict('records')\n",
    "    labels = list(df['label'])\n",
    "\n",
    "    return dict_for_vec, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-02T10:13:15.500455Z",
     "start_time": "2020-07-02T10:13:15.497987Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def dict_vectorizer_embed(training_dict, gold_dict):\n",
    "    '''\n",
    "    a function that takes two dictionaries of CoNLL data (training and test)\n",
    "    allows for embeddings\n",
    "    Returns vectors usable as input for machine learning calculations\n",
    "    '''\n",
    "    v = DictVectorizer()\n",
    "    training_vec = v.fit_transform(training_dict)\n",
    "    test_vec = v.transform(gold_dict)\n",
    "    test_array = test_vec.toarray()\n",
    "    training_array = training_vec.toarray()\n",
    "\n",
    "    return training_vec, test_vec, training_array, test_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-02T10:13:15.504072Z",
     "start_time": "2020-07-02T10:13:15.501394Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def concat_arrays(feature_array, embedding_list, domain_embeds):\n",
    "    '''\n",
    "    a feature for embeddings path which concatenates an array of features and\n",
    "    a list of feature vectors\n",
    "    returns one list of concatenated feature vectors and associated embeddings\n",
    "\n",
    "    '''\n",
    "    num_words = feature_array.shape[0]\n",
    "    concat_input = []  # for storing the result of concatenating\n",
    "    for index in range(num_words):\n",
    "        # concatenate features per word\n",
    "        representation = list(embedding_list[index]) + list(domain_embeds[index])+list(feature_array[index])\n",
    "#         representation = list(embedding_list[index]) + list(feature_array[index])\n",
    "\n",
    "        concat_input.append(representation)\n",
    "    return concat_input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "## adding additional pos information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-02T10:13:29.846191Z",
     "start_time": "2020-07-02T10:13:29.759390Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "features = ['xpos']\n",
    "\n",
    "training_dict, labels = dicts_n_labels(df_train, features)\n",
    "gold_dict, labels = dicts_n_labels(df_test, features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-02T10:13:37.919398Z",
     "start_time": "2020-07-02T10:13:37.907392Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def training_with_syntax (general_embed_model, custom_embed_model, dataframe_series, label_series, training_dict, gold_dict, gold_series, gold_label):\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    embeddings = embed_swap (general_embed_model, dataframe_series)\n",
    "    domain_embed = embed_swap (custom_embed_model, dataframe_series.fillna('na'))       \n",
    "    training_vec, test_vec, training_array, test_array = dict_vectorizer_embed(training_dict, gold_dict)\n",
    "    concat_training = concat_arrays(training_array, embeddings, domain_embed)\n",
    "    x_train = np.array(embeddings)\n",
    "    x_train= np.reshape(x_train, (1, x_train.shape[0], x_train.shape[1]))\n",
    "    X_tr = np.array(concat_training)\n",
    "    X_tr = np.reshape(X_tr, (1, X_tr.shape[0], X_tr.shape[1]))\n",
    "    X_train = X_tr[:,:23763,:]\n",
    "    \n",
    "    X_valid = X_tr[:,23763:,:]\n",
    "    \n",
    "    print('shape: x_valid :', X_valid.shape)\n",
    "    print('shape: X_train :', X_train.shape)  \n",
    "    train_labels, label_index = labels_to_categorical(label_series)\n",
    "    y_train = keras.utils.np_utils.to_categorical(train_labels)\n",
    "    y_train = np.reshape(y_train,(1,y_train.shape[0], y_train.shape[1]))\n",
    "    y_valid = y_train[:,23763:,:]\n",
    "    \n",
    "    y_train = y_train[:,:23763,:]\n",
    "    \n",
    "    print('shape: y_valid :', y_valid.shape)\n",
    "    print('shape: y_train :', y_train.shape) \n",
    "    test_embeddings = embed_swap (general_embed_model, gold_series)\n",
    "    domain_test = embed_swap (custom_embed_model, gold_series.fillna('na'))\n",
    "    \n",
    "    concat_test = concat_arrays(test_array, test_embeddings, domain_test)\n",
    "    test_labels, label_index = labels_to_categorical(gold_label)\n",
    "    y_test = keras.utils.np_utils.to_categorical(test_labels)\n",
    "    X_te = np.array(concat_test)\n",
    "    X_te = np.reshape(X_te, (1, X_te.shape[0], X_te.shape[1]))\n",
    "    print('shape: X_test :', X_te.shape)    \n",
    "    return X_train, y_train, X_valid, y_valid, X_te, test_labels, label_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-02T10:14:24.809499Z",
     "start_time": "2020-07-02T10:14:19.922372Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-11-147653972da2>:9: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
      "  if token in word_embedding_model:\n",
      "<ipython-input-11-147653972da2>:10: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  vector = word_embedding_model[token]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape: x_valid : (1, 23763, 446)\n",
      "shape: X_train : (1, 23763, 446)\n",
      "shape: y_valid : (1, 23763, 3)\n",
      "shape: y_train : (1, 23763, 3)\n",
      "shape: X_test : (1, 12752, 446)\n"
     ]
    }
   ],
   "source": [
    "X_train,  y_train, X_valid, y_valid, X_test, test_labels, label_index = training_with_syntax (w2v_embedding_model, xu_model, df_train['word'], df_train['label'], training_dict, gold_dict, df_test['word'], df_test['label'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-02T10:14:50.158510Z",
     "start_time": "2020-07-02T10:14:50.155254Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "embedding_dims = X_train.shape[2]\n",
    "kernel_size = 5\n",
    "epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-02T10:15:24.049454Z",
     "start_time": "2020-07-02T10:14:53.762278Z"
    },
    "hidden": true,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, None, 128)         285568    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, None, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, None, 128)         82048     \n",
      "_________________________________________________________________\n",
      "conv1d_3 (Conv1D)            (None, None, 256)         164096    \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, None, 256)         327936    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, None, 3)           771       \n",
      "=================================================================\n",
      "Total params: 860,419\n",
      "Trainable params: 860,419\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7f7a5728adf0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# matching hsu\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters = 128, kernel_size = kernel_size,padding='same', activation='relu',strides=1,input_shape = (None, embedding_dims)))\n",
    "model.add(Dropout(0.55,))\n",
    "model.add(Conv1D(filters = 128, kernel_size = kernel_size, padding='same', activation='relu'))\n",
    "model.add(Conv1D(filters = 256, kernel_size = kernel_size, padding='same'))\n",
    "model.add(Conv1D(filters = 256, kernel_size = kernel_size, padding='same'))\n",
    "# model.add(Conv1D(filters = 256, kernel_size = kernel_size, padding='same'))\n",
    "model.add(Dense(units=3, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, batch_size=batch_size, epochs=epochs, validation_data = (X_valid, y_valid), verbose = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "# Predict\n",
    "\n",
    "run 5 times and take mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-02T10:16:10.249256Z",
     "start_time": "2020-07-02T10:16:10.217911Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "output_list = model.predict_classes(X_test)\n",
    "#change df_gold where relevant\n",
    "gold_series = df_test.label.tolist()\n",
    "system_predictions = output_list[0]\n",
    "d = {'gold':gold_series,'predicted':system_predictions}\n",
    "result = pd.DataFrame(d)\n",
    "inv_map = {v: k for k, v in label_index.items()}\n",
    "predictions = result.predicted.map(inv_map)\n",
    "df_test['predicted'] = predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-07-02T10:16:57.751683Z",
     "start_time": "2020-07-02T10:16:57.257022Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           B       0.85      0.88      0.86      1132\n",
      "           I       0.89      0.56      0.69       571\n",
      "           O       0.98      0.99      0.98     11049\n",
      "\n",
      "    accuracy                           0.96     12752\n",
      "   macro avg       0.90      0.81      0.85     12752\n",
      "weighted avg       0.96      0.96      0.96     12752\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           B       0.93      0.84      0.88      1703\n",
      "           O       0.98      0.99      0.98     11049\n",
      "\n",
      "    accuracy                           0.97     12752\n",
      "   macro avg       0.95      0.91      0.93     12752\n",
      "weighted avg       0.97      0.97      0.97     12752\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_names = ['B','I','O']\n",
    "print(classification_report(result.gold, df_test.predicted, target_names=target_names))\n",
    "df_test['gold_bi']= result.gold.replace({'I': 'B'})\n",
    "df_test['predicted_bi']= df_test.predicted.replace({'I': 'B'})\n",
    "target_names = ['B','O']\n",
    "print(classification_report(df_test.gold_bi, df_test.predicted_bi, target_names=target_names))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
